{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6efdf76c-afb8-4005-b1b3-5b8578a6f93f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T11:56:25.207518Z",
     "iopub.status.busy": "2026-02-13T11:56:25.207342Z",
     "iopub.status.idle": "2026-02-13T11:56:29.678912Z",
     "shell.execute_reply": "2026-02-13T11:56:29.678418Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import glob\n",
    "import shutil\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import math\n",
    "from pathlib import Path\n",
    "import json\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "from types import SimpleNamespace\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "from scipy.integrate import solve_ivp\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.signal import find_peaks\n",
    "from autocatalytic_cores_lib import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "from scipy.optimize import newton_krylov\n",
    "from scipy.optimize import broyden1\n",
    "from scipy.optimize import anderson\n",
    "from scipy.optimize._nonlin import NoConvergence\n",
    "from sympy import symbols, Matrix, diff, lambdify\n",
    "from scipy.linalg import eigvals\n",
    "from numpy.linalg import svd\n",
    "from scipy.optimize import linprog\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import bmat\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "from scipy.linalg import eigh\n",
    "from scipy.optimize import fsolve\n",
    "from textwrap import dedent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4caaea9-3b5a-4962-a4ea-25712952acbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T11:56:29.681285Z",
     "iopub.status.busy": "2026-02-13T11:56:29.680947Z",
     "iopub.status.idle": "2026-02-13T11:56:29.699194Z",
     "shell.execute_reply": "2026-02-13T11:56:29.698637Z"
    }
   },
   "outputs": [],
   "source": [
    "class Neumann(object):\n",
    "\n",
    "    \"\"\"\n",
    "    This class describes the Generalized von Neumann growth model as it was\n",
    "    discussed in Kemeny et al. (1956, ECTA) and Gale (1960, Chapter 9.5):\n",
    "\n",
    "    Let:\n",
    "    n ... number of goods\n",
    "    m ... number of activities\n",
    "    A ... input matrix is m-by-n\n",
    "        a_{i,j} - amount of good j consumed by activity i\n",
    "    B ... output matrix is m-by-n\n",
    "        b_{i,j} - amount of good j produced by activity i\n",
    "\n",
    "    x ... intensity vector (m-vector) with non-negative entries\n",
    "        x'B - the vector of goods produced\n",
    "        x'A - the vector of goods consumed\n",
    "    p ... price vector (n-vector) with non-negative entries\n",
    "        Bp - the revenue vector for every activity\n",
    "        Ap - the cost of each activity\n",
    "\n",
    "    Both A and B have non-negative entries. Moreover, we assume that\n",
    "    (1) Assumption I (every good which is consumed is also produced):\n",
    "        for all j, b_{.,j} > 0, i.e. at least one entry is strictly positive\n",
    "    (2) Assumption II (no free lunch):\n",
    "        for all i, a_{i,.} > 0, i.e. at least one entry is strictly positive\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : array_like or scalar(float)\n",
    "        Part of the state transition equation.  It should be `n x n`\n",
    "    B : array_like or scalar(float)\n",
    "        Part of the state transition equation.  It should be `n x k`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, A, B):\n",
    "\n",
    "        self.A, self.B = list(map(self.convert, (A, B)))\n",
    "        self.m, self.n = self.A.shape\n",
    "\n",
    "        # Check if (A, B) satisfy the basic assumptions\n",
    "        assert self.A.shape == self.B.shape, 'The input and output matrices \\\n",
    "              must have the same dimensions!'\n",
    "        assert (self.A >= 0).all() and (self.B >= 0).all(), 'The input and \\\n",
    "              output matrices must have only non-negative entries!'\n",
    "\n",
    "        # (1) Check whether Assumption I is satisfied:\n",
    "        if (np.sum(B, 0) <= 0).any():\n",
    "            self.AI = False\n",
    "        else:\n",
    "            self.AI = True\n",
    "\n",
    "        # (2) Check whether Assumption II is satisfied:\n",
    "        if (np.sum(A, 1) <= 0).any():\n",
    "            self.AII = False\n",
    "        else:\n",
    "            self.AII = True\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "    def __str__(self):\n",
    "\n",
    "        me = \"\"\"\n",
    "        Generalized von Neumann expanding model:\n",
    "          - number of goods          : {n}\n",
    "          - number of activities     : {m}\n",
    "\n",
    "        Assumptions:\n",
    "          - AI:  every column of B has a positive entry    : {AI}\n",
    "          - AII: every row of A has a positive entry       : {AII}\n",
    "\n",
    "        \"\"\"\n",
    "        # Irreducible                                       : {irr}\n",
    "        return dedent(me.format(n=self.n, m=self.m,\n",
    "                                AI=self.AI, AII=self.AII))\n",
    "\n",
    "    def convert(self, x):\n",
    "        \"\"\"\n",
    "        Convert array_like objects (lists of lists, floats, etc.) into\n",
    "        well-formed 2D NumPy arrays\n",
    "        \"\"\"\n",
    "        return np.atleast_2d(np.asarray(x))\n",
    "\n",
    "\n",
    "    def bounds(self):\n",
    "        \"\"\"\n",
    "        Calculate the trivial upper and lower bounds for alpha (expansion rate)\n",
    "        and beta (interest factor). See the proof of Theorem 9.8 in Gale (1960)\n",
    "        \"\"\"\n",
    "\n",
    "        n, m = self.n, self.m\n",
    "        A, B = self.A, self.B\n",
    "\n",
    "        f = lambda α: ((B - α * A) @ np.ones((n, 1))).max()\n",
    "        g = lambda β: (np.ones((1, m)) @ (B - β * A)).min()\n",
    "\n",
    "        UB = fsolve(f, 1).item()  # Upper bound for α, β\n",
    "        LB = fsolve(g, 2).item()  # Lower bound for α, β\n",
    "\n",
    "        return LB, UB\n",
    "\n",
    "\n",
    "    def zerosum(self, γ, dual=False):\n",
    "        \"\"\"\n",
    "        Given gamma, calculate the value and optimal strategies of a\n",
    "        two-player zero-sum game given by the matrix\n",
    "\n",
    "                M(gamma) = B - gamma * A\n",
    "\n",
    "        Row player maximizing, column player minimizing\n",
    "\n",
    "        Zero-sum game as an LP (primal --> α)\n",
    "\n",
    "            max (0', 1) @ (x', v)\n",
    "            subject to\n",
    "            [-M', ones(n, 1)] @ (x', v)' <= 0\n",
    "            (x', v) @ (ones(m, 1), 0) = 1\n",
    "            (x', v) >= (0', -inf)\n",
    "\n",
    "        Zero-sum game as an LP (dual --> beta)\n",
    "\n",
    "            min (0', 1) @ (p', u)\n",
    "            subject to\n",
    "            [M, -ones(m, 1)] @ (p', u)' <= 0\n",
    "            (p', u) @ (ones(n, 1), 0) = 1\n",
    "            (p', u) >= (0', -inf)\n",
    "\n",
    "        Outputs:\n",
    "        --------\n",
    "        value: scalar\n",
    "            value of the zero-sum game\n",
    "\n",
    "        strategy: vector\n",
    "            if dual = False, it is the intensity vector,\n",
    "            if dual = True, it is the price vector\n",
    "        \"\"\"\n",
    "\n",
    "        A, B, n, m = self.A, self.B, self.n, self.m\n",
    "        M = B - γ * A\n",
    "\n",
    "        if dual == False:\n",
    "            # Solve the primal LP (for details see the description)\n",
    "            # (1) Define the problem for v as a maximization (linprog minimizes)\n",
    "            c = np.hstack([np.zeros(m), -1])\n",
    "\n",
    "            # (2) Add constraints :\n",
    "            # ... non-negativity constraints\n",
    "            bounds = tuple(m * [(0, None)] + [(None, None)])\n",
    "            # ... inequality constraints\n",
    "            A_iq = np.hstack([-M.T, np.ones((n, 1))])\n",
    "            b_iq = np.zeros((n, 1))\n",
    "            # ... normalization\n",
    "            A_eq = np.hstack([np.ones(m), 0]).reshape(1, m + 1)\n",
    "            b_eq = 1\n",
    "\n",
    "            res = linprog(c, A_ub=A_iq, b_ub=b_iq, A_eq=A_eq, b_eq=b_eq,\n",
    "                          bounds=bounds)\n",
    "\n",
    "        else:\n",
    "            # Solve the dual LP (for details see the description)\n",
    "            # (1) Define the problem for v as a maximization (linprog minimizes)\n",
    "            c = np.hstack([np.zeros(n), 1])\n",
    "\n",
    "            # (2) Add constraints :\n",
    "            # ... non-negativity constraints\n",
    "            bounds = tuple(n * [(0, None)] + [(None, None)])\n",
    "            # ... inequality constraints\n",
    "            A_iq = np.hstack([M, -np.ones((m, 1))])\n",
    "            b_iq = np.zeros((m, 1))\n",
    "            # ... normalization\n",
    "            A_eq = np.hstack([np.ones(n), 0]).reshape(1, n + 1)\n",
    "            b_eq = 1\n",
    "\n",
    "            res = linprog(c, A_ub=A_iq, b_ub=b_iq, A_eq=A_eq, b_eq=b_eq,\n",
    "                          bounds=bounds)\n",
    "\n",
    "        if res.status != 0 or res.x is None:\n",
    "            # LP infeasible or error\n",
    "            return np.nan, None\n",
    "\n",
    "        # Pull out the required quantities\n",
    "        value = res.x[-1]\n",
    "        strategy = res.x[:-1]\n",
    "\n",
    "        return value, strategy\n",
    "\n",
    "\n",
    "    def expansion(self, tol=1e-8, maxit=1000):\n",
    "        \"\"\"\n",
    "        The algorithm used here is described in Hamburger-Thompson-Weil\n",
    "        (1967, ECTA). It is based on a simple bisection argument and utilizes\n",
    "        the idea that for a given γ (= α or β), the matrix \"M = B - γ * A\"\n",
    "        defines a two-player zero-sum game, where the optimal strategies are\n",
    "        the (normalized) intensity and price vector.\n",
    "\n",
    "        Outputs:\n",
    "        --------\n",
    "        alpha: scalar\n",
    "            optimal expansion rate\n",
    "        \"\"\"\n",
    "\n",
    "        LB, UB = self.bounds()\n",
    "\n",
    "        for iter in range(maxit):\n",
    "\n",
    "            γ = (LB + UB) / 2\n",
    "            ZS = self.zerosum(γ=γ, dual=False)\n",
    "            V = ZS[0]     # value of the game with γ\n",
    "\n",
    "            if V >= 0:\n",
    "                LB = γ\n",
    "            else:\n",
    "                UB = γ\n",
    "\n",
    "            if abs(UB - LB) < tol:\n",
    "                γ = (UB + LB) / 2\n",
    "                x = self.zerosum(γ=γ)[1]\n",
    "                p = self.zerosum(γ=γ, dual=True)[1]\n",
    "                break\n",
    "\n",
    "        return γ, x, p\n",
    "\n",
    "    def interest(self, tol=1e-8, maxit=1000):\n",
    "        \"\"\"\n",
    "        The algorithm used here is described in Hamburger-Thompson-Weil\n",
    "        (1967, ECTA). It is based on a simple bisection argument and utilizes\n",
    "        the idea that for a given gamma (= alpha or beta),\n",
    "        the matrix \"M = B - γ * A\" defines a two-player zero-sum game,\n",
    "        where the optimal strategies are the (normalized) intensity and price\n",
    "        vector\n",
    "\n",
    "        Outputs:\n",
    "        --------\n",
    "        beta: scalar\n",
    "            optimal interest rate\n",
    "        \"\"\"\n",
    "\n",
    "        LB, UB = self.bounds()\n",
    "\n",
    "        for iter in range(maxit):\n",
    "            γ = (LB + UB) / 2\n",
    "            ZS = self.zerosum(γ=γ, dual=True)\n",
    "            V = ZS[0]\n",
    "\n",
    "            if V > 0:\n",
    "                LB = γ\n",
    "            else:\n",
    "                UB = γ\n",
    "\n",
    "            if abs(UB - LB) < tol:\n",
    "                γ = (UB + LB) / 2\n",
    "                p = self.zerosum(γ=γ, dual=True)[1]\n",
    "                x = self.zerosum(γ=γ)[1]\n",
    "                break\n",
    "\n",
    "        return γ, x, p\n",
    "\n",
    "def compute_von_neumann_alpha_beta(S_plus, S_minus, tol=1e-8):\n",
    "    \"\"\"\n",
    "    Compute von Neumann alpha (expansion), beta (interest),\n",
    "    and the optimal normalized flows for both problems.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    alpha : Optimal expansion rate.\n",
    "    beta : Optimal interest rate.\n",
    "    x_alpha : Optimal intensity vector (normalized flow) for expansion.\n",
    "    p_alpha : Optimal price vector for expansion.\n",
    "    x_beta : Optimal intensity vector (normalized flow) for interest.\n",
    "    p_beta : Optimal price vector for interest.\n",
    "    \"\"\"\n",
    "    \n",
    "    A = S_minus.T\n",
    "    B = S_plus.T\n",
    "    model = Neumann(A, B)\n",
    "\n",
    "    # alpha\n",
    "    alpha, x_alpha, p_alpha = model.expansion(tol=tol)\n",
    "\n",
    "    # beta\n",
    "    beta, x_beta, p_beta  = model.interest(tol=tol)\n",
    "\n",
    "    return alpha, beta, x_alpha, p_alpha, x_beta, p_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33f6dc7a-5255-4ba2-a967-c02ca1f74edb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T11:56:29.701125Z",
     "iopub.status.busy": "2026-02-13T11:56:29.700827Z",
     "iopub.status.idle": "2026-02-13T11:56:29.704556Z",
     "shell.execute_reply": "2026-02-13T11:56:29.704176Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Praful MGF\n",
    "'''\n",
    "import algorithm_1 as algo1\n",
    "import auxiliary_functions as aux\n",
    "# import algorithm_3 as algo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83c1e4e0-5559-4670-8259-ca368e5a4b15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T11:56:29.706205Z",
     "iopub.status.busy": "2026-02-13T11:56:29.706012Z",
     "iopub.status.idle": "2026-02-13T11:56:29.714582Z",
     "shell.execute_reply": "2026-02-13T11:56:29.714180Z"
    }
   },
   "outputs": [],
   "source": [
    "def Generate_Random_Network(N_Y_raw, N_R_raw, ambiguity, max_order_f, max_order_b):\n",
    "\n",
    "    # Build Random Network\n",
    "    S_raw = np.zeros((N_Y_raw, N_R_raw))\n",
    "    S1_raw = np.zeros((N_Y_raw, N_R_raw))\n",
    "    \n",
    "    # Construct stoichiometric matrix\n",
    "    for i in range(N_R_raw):\n",
    "        species1 = random.randint(0, N_Y_raw - 1)\n",
    "        S_raw[species1][i] += 1\n",
    "        \n",
    "        species2 = random.randint(0, N_Y_raw - 1)\n",
    "        while not ambiguity and species2 == species1:\n",
    "            species2 = random.randint(0, N_Y_raw - 1)\n",
    "        S1_raw[species2][i] += 1\n",
    "            \n",
    "        # The order of a chemical reaction\n",
    "        if i == 0:\n",
    "            # Force at least one reaction to hit the maximum order (forward OR backward)\n",
    "            if random.random() < 0.5:\n",
    "                total_order_for = max_order_f\n",
    "                total_order_bac = random.randint(1, max_order_b)\n",
    "            else:\n",
    "                total_order_for = random.randint(1, max_order_f)\n",
    "                total_order_bac = max_order_b\n",
    "        else:\n",
    "            total_order_for = random.randint(1, max_order_f)\n",
    "            total_order_bac = random.randint(1, max_order_b)\n",
    "\n",
    "        # Count the number of forward/backward reaction species already in the reaction\n",
    "        stoichio_for = 0\n",
    "        stoichio_bac = 0\n",
    "                \n",
    "        while stoichio_for < (total_order_for - 1):\n",
    "            species = random.randint(0, N_Y_raw - 1)\n",
    "            if ambiguity or S1_raw[species][i] == 0:\n",
    "                S_raw[species][i] += 1\n",
    "                stoichio_for += 1\n",
    "    \n",
    "        while stoichio_bac < (total_order_bac - 1):\n",
    "            species = random.randint(0, N_Y_raw - 1)\n",
    "            if ambiguity or S_raw[species][i] == 0:\n",
    "                S1_raw[species][i] += 1\n",
    "                stoichio_bac += 1\n",
    "    \n",
    "    Stot_raw = S1_raw - S_raw\n",
    "\n",
    "    '''\n",
    "    Reduce Matrix to Avoid Redundant and Confusion\n",
    "    '''\n",
    "    \n",
    "    # Remove all-zero rows (empty species)\n",
    "    # Species\n",
    "    row_keep = ~((S_raw==0).all(axis=1) & (S1_raw==0).all(axis=1))\n",
    "    S_raw  = S_raw[row_keep]\n",
    "    S1_raw = S1_raw[row_keep]\n",
    "\n",
    "    # Remove all-zero columns (reactions with net zero stoichiometry)\n",
    "    col_keep = ~((S_raw==0).all(axis=0) & (S1_raw==0).all(axis=0))\n",
    "    S_raw  = S_raw[:, col_keep]\n",
    "    S1_raw = S1_raw[:, col_keep]\n",
    "\n",
    "    # Remove duplicate columns\n",
    "    m = S_raw.shape[1]\n",
    "    keep = []\n",
    "    seen = set()\n",
    "    for j in range(m):\n",
    "        key = tuple(S_raw[:,j].tolist()) + tuple(S1_raw[:,j].tolist())\n",
    "        if key not in seen:\n",
    "            seen.add(key)\n",
    "            keep.append(j)\n",
    "    S_raw  = S_raw[:, keep]\n",
    "    S1_raw = S1_raw[:, keep]\n",
    "\n",
    "\n",
    "    # Record new parameters\n",
    "    S_plus = S1_raw\n",
    "    S_minus = S_raw\n",
    "    Stot = S_plus - S_minus\n",
    "    N_Y = Stot.shape[0]\n",
    "    N_R = Stot.shape[1]\n",
    "\n",
    "    df_Stot = pd.DataFrame(\n",
    "    Stot.astype(int),                        \n",
    "    index=range(1, Stot.shape[0]+1),         \n",
    "    columns=range(1, Stot.shape[1]+1)        \n",
    "    )\n",
    "    #print(\"Matrix Stot:\")\n",
    "    #print(df_Stot.to_string())\n",
    "    \n",
    "    # S_plus \n",
    "    df_Sp = pd.DataFrame(\n",
    "        S_plus.astype(int),\n",
    "        index=range(1, S_plus.shape[0]+1),\n",
    "        columns=range(1, S_plus.shape[1]+1)\n",
    "    )\n",
    "    #print(\"\\nS_plus:\")\n",
    "    #print(df_Sp.to_string())\n",
    "    \n",
    "    # S_minus \n",
    "    df_Sm = pd.DataFrame(\n",
    "        S_minus.astype(int),\n",
    "        index=range(1, S_minus.shape[0]+1),\n",
    "        columns=range(1, S_minus.shape[1]+1)\n",
    "    )\n",
    "    #print(\"\\nS_minus:\")\n",
    "    #print(df_Sm.to_string())\n",
    "    #print(\"NY =\", N_Y)\n",
    "    #print(\"NR =\", N_R)\n",
    "\n",
    "    return Stot, N_Y, N_R, S_plus, S_minus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b47d3e3-58a1-48cd-90ca-793c016c1d00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T11:56:29.716156Z",
     "iopub.status.busy": "2026-02-13T11:56:29.715982Z",
     "iopub.status.idle": "2026-02-13T11:56:29.719453Z",
     "shell.execute_reply": "2026-02-13T11:56:29.719064Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We only consider forward reactions,\n",
    "we don't need to define chemical potential and delta G\n",
    "\"\"\"\n",
    "\n",
    "def Construct_Kinetics(N_Y, N_R, S_plus, S_minus, degradation=False):\n",
    "    \"\"\"\n",
    "      - Initial concentration Y0\n",
    "      - Generalized Forward Rate constant kf\n",
    "      - Degradation kd\n",
    "    \"\"\"\n",
    "    Y0 = [random.uniform(1, 100.0) for _ in range(N_Y)]\n",
    "\n",
    "    kf = np.array([random.uniform(1e-12, 1.0) for _ in range(N_R)])\n",
    "    #kf = np.array([(1.0) for _ in range(N_R)])\n",
    "\n",
    "    kf /= kf.max()\n",
    "    \n",
    "    # degradation degradation coefficient\n",
    "    kd = None\n",
    "    if degradation:\n",
    "        kd = 0.01 * np.array([random.uniform(0.95, 1.05) for _ in range(N_Y)])\n",
    "\n",
    "    return np.array(Y0), kf, kd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17461163-78c8-401d-8da8-2e7d69dc8a6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T11:56:29.721088Z",
     "iopub.status.busy": "2026-02-13T11:56:29.720917Z",
     "iopub.status.idle": "2026-02-13T11:56:29.731621Z",
     "shell.execute_reply": "2026-02-13T11:56:29.731175Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_dydt_rescaled_func(N_Y, N_R, S_minus, S_plus, kf, kd, law = \"MA\"):\n",
    "    eps=1e-12\n",
    "    lambdas = []\n",
    "        \n",
    "    # net stoichiometry in the free (Y) part for each reaction l\n",
    "    netStoich_Y = np.zeros(N_R, dtype=int)\n",
    "    for l in range(N_R):\n",
    "        netStoich_Y[l] = int(np.sum(S_plus[0:, l]) - np.sum(S_minus[0:, l]))\n",
    "\n",
    "    def dydt_rescaled(t, Y_star_full):\n",
    "        Ys = Y_star_full[:N_Y]      # normalized Y^*(t)\n",
    "        Ys = np.clip(Ys, eps, None) \n",
    "        Ys /= Ys.sum()\n",
    "        \n",
    "        logN = Y_star_full[-1]      # logN(t)\n",
    "\n",
    "        net_flux = np.zeros(N_R)\n",
    "\n",
    "        for l in range(N_R):\n",
    "            # --- forward flux density using Ystar ---\n",
    "            prodY = 1.0\n",
    "            for j in range(N_Y):\n",
    "                p = S_minus[j, l]\n",
    "                if p>0:\n",
    "                    prodY *= Ys[j]**p\n",
    "\n",
    "            if np.sum(S_minus[0:, l])==0:\n",
    "                v_f = 0.0\n",
    "            else:\n",
    "                if law==\"MM\":\n",
    "                    Kf = prodY\n",
    "                    v_f = 0.0 if (kf[l]+Kf)==0 else Kf/(kf[l]+Kf)\n",
    "                else:\n",
    "                    v_f = kf[l]*prodY\n",
    "\n",
    "            net_flux[l] = v_f\n",
    "            \n",
    "        lambda_t = float(np.dot(net_flux, netStoich_Y))\n",
    "        lambdas.append(lambda_t)\n",
    "\n",
    "        # dY*/dt\n",
    "        dYs = np.zeros(N_Y)\n",
    "        for j in range(N_Y):\n",
    "            row = S_plus[j,:] - S_minus[j,:]\n",
    "            dYs[j] = float(np.dot(row, net_flux)) - lambda_t*Ys[j]\n",
    "\n",
    "        # d(logN)/dt = lambda(t)\n",
    "        return np.concatenate([dYs, [lambda_t]])\n",
    "\n",
    "    return dydt_rescaled, lambdas\n",
    "    \n",
    "def Solve_Scaled_System(S_minus, S_plus, Y0, N_Y, N_R,\n",
    "                        kf, kd, dt, n_steps, threshold, extra_steps, law = \"MA\"):\n",
    "    \"\"\"\n",
    "    Fix step dt，simulate n_steps：\n",
    "      - t_eval      (length = n_steps+1)\n",
    "      - Ystar_traj  (shape (N_Y, n_steps+1))\n",
    "      - Yabs_traj   (shape (N_Y, n_steps+1))\n",
    "      - lambdas     (length = n_steps+1)\n",
    "      - N_traj      (length = n_steps+1)\n",
    "    \"\"\"\n",
    "    def single_run(Y0, n_steps):\n",
    "        # initialize N, normalize Y*\n",
    "        N0 = np.sum(Y0)\n",
    "        Ystar0 = Y0 / N0\n",
    "        logN0 = math.log(N0)\n",
    "        y0 = np.concatenate([Ystar0, [logN0]])\n",
    "    \n",
    "        ttot = dt * n_steps\n",
    "        t_eval = np.linspace(0, ttot, n_steps + 1)\n",
    "    \n",
    "        dydt_rescaled, lambdas = make_dydt_rescaled_func(\n",
    "            N_Y, N_R, S_minus, S_plus, kf, kd, law\n",
    "        )\n",
    "    \n",
    "        sol = solve_ivp(\n",
    "            fun=lambda t, y: dydt_rescaled(t, y),\n",
    "            t_span=[0, ttot],\n",
    "            y0=y0,\n",
    "            method=\"LSODA\",\n",
    "            dense_output=False,\n",
    "            t_eval=t_eval,\n",
    "            rtol=1e-6,\n",
    "            atol=1e-8\n",
    "        )\n",
    "    \n",
    "        Ystar_traj = sol.y[:N_Y, :]             # normalize Y^*(t)\n",
    "        logN_traj = sol.y[N_Y, :]               # logN(t)\n",
    "        N_traj = np.exp(logN_traj)              # exact N(t)\n",
    "        Yabs_traj = Ystar_traj * N_traj         # exact Y(t) = N(t)*Y^*(t)\n",
    "    \n",
    "        return t_eval, Ystar_traj, Yabs_traj, lambdas, N_traj, dydt_rescaled\n",
    "\n",
    "    t_eval, Ystar_traj, Yabs_traj, lambdas, N_traj, dydt_rescaled = single_run(Y0, n_steps)\n",
    "\n",
    "    \"\"\"\n",
    "    compute the residual of differencial equation and check if it reach the convergence requirement\n",
    "    and add additional steps if not\n",
    "    \"\"\"\n",
    "    \n",
    "    while True:\n",
    "        # the last time point\n",
    "        q_final = Ystar_traj[:, -1]\n",
    "        lambda_final = lambdas[-1]\n",
    "        logN_final = math.log(N_traj[-1])\n",
    "        # compute residual dY*/dt\n",
    "        d_full = dydt_rescaled(0.0, np.concatenate([q_final, [logN_final]]))\n",
    "        residual = np.max(np.abs(d_full[:N_Y]))\n",
    "        if residual < threshold:\n",
    "            break\n",
    "\n",
    "        # if need to run extra_steps\n",
    "        Y0_new = Yabs_traj[:, -1]\n",
    "        t_ext, Ystar_ext, Yabs_ext, lambda_ext, N_ext, _ = single_run(Y0_new, extra_steps)\n",
    "\n",
    "        # conjugate data\n",
    "        t_ext_shifted = t_ext[1:] + t_eval[-1]\n",
    "        t_eval = np.concatenate([t_eval, t_ext_shifted])\n",
    "        Ystar_traj = np.hstack([Ystar_traj, Ystar_ext[:, 1:]])\n",
    "        Yabs_traj  = np.hstack([Yabs_traj,  Yabs_ext[:,  1:]])\n",
    "        lambdas    = lambdas + lambda_ext[1:]\n",
    "        N_traj     = np.concatenate([N_traj, N_ext[1:]])\n",
    "\n",
    "    return t_eval, Ystar_traj, Yabs_traj, lambdas, N_traj\n",
    "    \n",
    "# =============================================================================\n",
    "# long-term growth rate\n",
    "# =============================================================================\n",
    "def compute_long_term_growth_rate(lambdas):\n",
    "    \"\"\"\n",
    "    Average the last last_n values of the lambda(t) sequence to obtain an estimate of the exponential growth rate λ\n",
    "    \"\"\"\n",
    "    if len(lambdas) == 0:\n",
    "       return 0.0\n",
    "    return lambdas[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb3653cb-1f59-4dcb-b339-fd0dcebdfdae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T11:56:29.733246Z",
     "iopub.status.busy": "2026-02-13T11:56:29.733054Z",
     "iopub.status.idle": "2026-02-13T11:56:29.744304Z",
     "shell.execute_reply": "2026-02-13T11:56:29.743827Z"
    }
   },
   "outputs": [],
   "source": [
    "def solve_steadystate_by_newton_krylov(\n",
    "    S_plus, S_minus, N_Y, N_R, Y0, kf,\n",
    "    law='MA',\n",
    "    dt=1e-3, n_steps=20000,\n",
    "    tol=1e-7, maxiter=5000, inner_maxiter=200): \n",
    "    '''\n",
    "    Perform time-dependent simulation until t = dt * n_steps, obtaining initial q0, lambda0.\n",
    "    Solve F(q,λ)=0 using Newton–Krylov, with parameterization ensuring q ∈ simplex.\n",
    "    '''\n",
    "    # =============================================================================\n",
    "    # —— Simulation for some steps to get initial condition for equation —— \n",
    "    # =============================================================================\n",
    "    lambdas = []\n",
    "    Y0 = np.asarray(Y0, float)\n",
    "    N0 = Y0.sum()\n",
    "    Ystar0 = Y0 / N0\n",
    "    logN0 = np.log(N0)\n",
    "    y0 = np.concatenate([Ystar0, [logN0]])\n",
    "\n",
    "    # netStoich\n",
    "    netStoich_Y = np.zeros(N_R, dtype=int)\n",
    "    for l in range(N_R):\n",
    "        netStoich_Y[l] = int(np.sum(S_plus[0:, l]) - np.sum(S_minus[0:, l]))\n",
    "\n",
    "    def dydt_rescaled(t, y):\n",
    "        Ys = y[:N_Y]\n",
    "        Ys = np.clip(Ys, 1e-12, None)\n",
    "        Ys /= Ys.sum()\n",
    "        \n",
    "        net_flux = np.zeros(N_R)\n",
    "\n",
    "        for l in range(N_R):\n",
    "            # --- forward flux density using Ystar ---\n",
    "            prodY = 1.0\n",
    "            for j in range(N_Y):\n",
    "                p = S_minus[j, l]\n",
    "                if p>0:\n",
    "                    prodY *= Ys[j]**p\n",
    "\n",
    "            if np.sum(S_minus[0:, l])==0:\n",
    "                v_f = 0.0\n",
    "            else:\n",
    "                if law==\"MM\":\n",
    "                    Kf = prodY\n",
    "                    v_f = 0.0 if (kf[l]+Kf)==0 else Kf/(kf[l]+Kf)\n",
    "                else:\n",
    "                    v_f = kf[l]*prodY\n",
    "\n",
    "            net_flux[l] = v_f\n",
    "            \n",
    "        lambda_t = float(np.dot(net_flux, netStoich_Y))\n",
    "        lambdas.append(lambda_t)\n",
    "\n",
    "        # dY*/dt\n",
    "        dYs = np.zeros(N_Y)\n",
    "        for j in range(N_Y):\n",
    "            row = S_plus[j,:] - S_minus[j,:]\n",
    "            dYs[j] = float(np.dot(row, net_flux)) - lambda_t*Ys[j]\n",
    "\n",
    "        # d(logN)/dt = lambda(t)\n",
    "        return np.concatenate([dYs, [lambda_t]])\n",
    "\n",
    "    ttot = dt * n_steps\n",
    "    t_eval = np.linspace(0, ttot, n_steps + 1)\n",
    "    sol = solve_ivp(\n",
    "        fun=dydt_rescaled,\n",
    "        t_span=[0, ttot],\n",
    "        y0=y0,\n",
    "        method=\"LSODA\",\n",
    "        t_eval=t_eval,\n",
    "        rtol=1e-6, atol=1e-8\n",
    "    )\n",
    "    Ystar_traj = sol.y[:N_Y, :]\n",
    "    Ys_final = Ystar_traj[:, -1]\n",
    "\n",
    "    # initial guess q0, lambda0\n",
    "    q0 = np.clip(Ys_final, 1e-12, None)\n",
    "    q0 /= q0.sum()\n",
    "    J0 = np.array([\n",
    "        kf[r] * np.prod(q0**S_minus[:, r])\n",
    "        for r in range(N_R)\n",
    "    ])\n",
    "    lam0 = float(netStoich_Y.dot(J0))\n",
    "\n",
    "    # =============================================================================\n",
    "    # —— Newton–Krylov solve steady state equation —— \n",
    "    #    Parameterization: u_vars ∈ ℝ^(N_Y-1)， λ ∈ ℝ\n",
    "    # =============================================================================\n",
    "\n",
    "    # construct residual: x = [u_vars (N_Y-1), λ]\n",
    "    def residual_mapped(x):\n",
    "        u_vars = x[:N_Y-1]\n",
    "        lam = x[N_Y-1]\n",
    "        # rebuild u_full, set u_N=0\n",
    "        u_full = np.concatenate([u_vars, [0.0]])\n",
    "        # use softmax projection to q\n",
    "        expu = np.exp(u_full - u_full.max())\n",
    "        q = expu / expu.sum()\n",
    "        # compute flow\n",
    "        J = np.array([\n",
    "            kf[r] * np.prod(q**S_minus[:, r])\n",
    "            for r in range(N_R)\n",
    "        ])\n",
    "        # F(q, λ) = S*J - λ*q\n",
    "        return (S_plus - S_minus).dot(J) - lam * q\n",
    "\n",
    "    # initial x0: use q0 project back to u0_vars\n",
    "    u0_full = np.log(q0)\n",
    "    # gauge: set u_N = 0, others minus u_N\n",
    "    u0_vars = u0_full[:-1] - u0_full[-1]\n",
    "    x0 = np.concatenate([u0_vars, [lam0]])\n",
    "    \n",
    "    try:\n",
    "        sol_nk = newton_krylov(\n",
    "            residual_mapped,\n",
    "            x0,\n",
    "            method='lgmres',\n",
    "            inner_maxiter=inner_maxiter,\n",
    "            f_tol=tol,\n",
    "            maxiter=maxiter,\n",
    "            line_search=True,\n",
    "        )\n",
    "        \n",
    "    except Exception as e_krylov:\n",
    "        sol_nk = broyden1(\n",
    "            residual_mapped,\n",
    "            x0,\n",
    "            f_tol=tol,\n",
    "            maxiter=maxiter\n",
    "        )\n",
    "        \n",
    "    except Exception as e_broyden:\n",
    "        sol_nk = anderson(\n",
    "            residual_mapped,\n",
    "            x0,\n",
    "            f_tol=tol,\n",
    "            maxiter=maxiter\n",
    "        )\n",
    "\n",
    "    # slove q*, λ*\n",
    "    u_star_vars = sol_nk[:N_Y-1]\n",
    "    lam_star   = sol_nk[N_Y-1]\n",
    "    u_star_full = np.concatenate([u_star_vars, [0.0]])\n",
    "    expu = np.exp(u_star_full - u_star_full.max())\n",
    "    q_star = expu / expu.sum()\n",
    "\n",
    "    # final J_star\n",
    "    J_star = np.array([\n",
    "        kf[r] * np.prod(q_star**S_minus[:, r])\n",
    "        for r in range(N_R)\n",
    "    ])\n",
    "\n",
    "    return q_star, lam_star, J_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "789cc727-b4fc-4b55-b440-12e2d1d2fb00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T11:56:29.746282Z",
     "iopub.status.busy": "2026-02-13T11:56:29.746081Z",
     "iopub.status.idle": "2026-02-13T11:56:29.749192Z",
     "shell.execute_reply": "2026-02-13T11:56:29.748713Z"
    }
   },
   "outputs": [],
   "source": [
    "# compute the topological growth bound\n",
    "def compute_topological_growth_bound(S_minus, alpha):\n",
    "    row_sums = np.sum(S_minus, axis=1)\n",
    "    S_minus_norm = np.max(row_sums)\n",
    "    mu = S_minus_norm * (alpha - 1)\n",
    "    return mu\n",
    "\n",
    "# compute the lower topological growth bound\n",
    "def compute_lower_topological_growth_bound(S_minus):\n",
    "    row_sums = np.sum(S_minus, axis=1)\n",
    "    S_minus_norm = np.max(row_sums)\n",
    "    mu = - S_minus_norm\n",
    "    return mu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd9057d-8d9b-4f61-8e78-71fb34db80b8",
   "metadata": {},
   "source": [
    "# Random network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f53f242-4da9-4f7d-a28e-d12d35e3e4d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T11:56:29.751336Z",
     "iopub.status.busy": "2026-02-13T11:56:29.751150Z",
     "iopub.status.idle": "2026-02-13T11:56:29.758013Z",
     "shell.execute_reply": "2026-02-13T11:56:29.757612Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_all_results(base_folder,\n",
    "                     growth_list,\n",
    "                     S_plus_list, S_minus_list,\n",
    "                     kf_list, kd_list):\n",
    "    os.makedirs(base_folder, exist_ok=True)\n",
    "\n",
    "    DECIMALS = 4  # keep only 1e-4 in saved outputs\n",
    "\n",
    "    # 1) Growth factors table\n",
    "    df_growth = pd.DataFrame(growth_list).sort_values('realization')\n",
    "    df_growth = df_growth.round(DECIMALS)\n",
    "    df_growth.to_csv(os.path.join(base_folder, 'growth_factors.dat'),\n",
    "                     sep='\t', index=False,\n",
    "                     float_format=f'%.{DECIMALS}f')\n",
    "\n",
    "    # 2) Formatted stoichiometric matrices, one file with all realizations\n",
    "    fmt_path = os.path.join(base_folder, 'stoichiometries_formatted.txt')\n",
    "    with open(fmt_path, 'w') as f:\n",
    "        for rec, S_plus, S_minus in zip(growth_list, S_plus_list, S_minus_list):\n",
    "            i = rec['realization']\n",
    "            f.write(f\"# Realization {i}\\n\")\n",
    "\n",
    "            # S_plus\n",
    "            df_sp = pd.DataFrame(\n",
    "                S_plus.astype(int),\n",
    "                index=range(1, S_plus.shape[0]+1),\n",
    "                columns=range(1, S_plus.shape[1]+1)\n",
    "            )\n",
    "            f.write(\"S_plus:\\n\")\n",
    "            f.write(df_sp.to_string())\n",
    "            f.write(\"\\n\\n\")\n",
    "\n",
    "            # S_minus\n",
    "            df_sm = pd.DataFrame(\n",
    "                S_minus.astype(int),\n",
    "                index=range(1, S_minus.shape[0]+1),\n",
    "                columns=range(1, S_minus.shape[1]+1)\n",
    "            )\n",
    "            f.write(\"S_minus:\\n\")\n",
    "            f.write(df_sm.to_string())\n",
    "            f.write(\"\\n\\n\")\n",
    "\n",
    "    # 3) Kinetics and initial concentrations table (long format)\n",
    "    kin_records = []\n",
    "    for rec, kf, kd in zip(growth_list, kf_list, kd_list):\n",
    "        i = rec['realization']\n",
    "        # kf\n",
    "        for idx, val in enumerate(kf):\n",
    "            kin_records.append({\n",
    "                'realization': i,\n",
    "                'parameter': 'kf',\n",
    "                'index': idx,\n",
    "                'value': round(float(val), DECIMALS)\n",
    "            })\n",
    "        # kd (ensure iterable)\n",
    "        kd_array = kd if kd is not None else np.full_like(kf, np.nan)\n",
    "        for idx, val in enumerate(kd_array):\n",
    "            kin_records.append({\n",
    "                'realization': i,\n",
    "                'parameter': 'kd',\n",
    "                'index': idx,\n",
    "                'value': round(float(val), DECIMALS)\n",
    "            })\n",
    "\n",
    "    df_kin = pd.DataFrame(kin_records) \\\n",
    "               .sort_values(['realization','parameter','index'])\n",
    "    df_kin = df_kin.round(DECIMALS)\n",
    "    df_kin.to_csv(os.path.join(base_folder, 'kinetics.dat'),\n",
    "                  sep='\t', index=False,\n",
    "                  float_format=f'%.{DECIMALS}f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9ddbf81-289b-4a9c-9155-292a4c00b76d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T11:56:29.759949Z",
     "iopub.status.busy": "2026-02-13T11:56:29.759769Z",
     "iopub.status.idle": "2026-02-13T11:56:29.788918Z",
     "shell.execute_reply": "2026-02-13T11:56:29.788377Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Stoichometric autocatalytic and dynamic growth\n",
    "\n",
    "Systems for maximum chemical reaction order = 2\n",
    "\n",
    "With autonomous check for matrix without X species\n",
    "\n",
    "With the check w^T · S\n",
    "'''\n",
    "\n",
    "def main_order2():\n",
    "\n",
    "    # --- recording precision only (do NOT change simulation precision) ---\n",
    "    SAVE_EPS = 1e-4\n",
    "    def q(x, eps=SAVE_EPS):\n",
    "        x = np.asarray(x, dtype=float)\n",
    "        return np.round(x / eps) * eps\n",
    "    def q1(x, eps=SAVE_EPS):\n",
    "        return float(np.round(float(x) / eps) * eps)\n",
    "    # ---------------------------------------------------------------------\n",
    "\n",
    "    # how many of each category\n",
    "    quota_ge1 = 60000   # α >= 1  (merge α=1 and α>1)\n",
    "    quota_lt1 = 40000   # α < 1\n",
    "    total_target = quota_ge1 + quota_lt1\n",
    "    next_pct = 10\n",
    "    \n",
    "    # counters\n",
    "    count_ge1 = 0\n",
    "    count_lt1 = 0\n",
    "\n",
    "    tol_alpha = 1e-4  # classification tolerance, keep consistent everywhere\n",
    "\n",
    "    # storage\n",
    "    results_gt1 = []\n",
    "    results_eq1 = []\n",
    "    results_lt1 = []\n",
    "\n",
    "    # counters\n",
    "    count_gt1 = 0\n",
    "    count_eq1 = 0\n",
    "    count_lt1 = 0\n",
    "    \n",
    "    # storage\n",
    "    alpha_list = []\n",
    "    beta_list = []\n",
    "    lambda_list = []\n",
    "    mu_list = []\n",
    "    mu_l_list = []\n",
    "    growth_list = []\n",
    "    S_plus_list = []\n",
    "    S_minus_list = []\n",
    "    kf_list = []; kd_list = []\n",
    "    delta_list = []\n",
    "    u_list = []              # u(S) = max(0, alpha-1)\n",
    "    B_list = []              # B(S) = ||S_-|| * ||k||\n",
    "    lam_tilde_list = [] \n",
    "    \n",
    "    attempts = 0       \n",
    "    successes = 0       \n",
    "    violation_list = []   # one bool per accepted sample\n",
    "    \n",
    "    # number of trail\n",
    "    while attempts < 10000000:\n",
    "        attempts += 1\n",
    "        \n",
    "        # Random networks (change the oder here)\n",
    "        Stot, N_Y, N_R, S_plus, S_minus = Generate_Random_Network(\n",
    "        N_Y_raw=random.randint(2, 12),\n",
    "        N_R_raw=random.randint(2, 12),\n",
    "        ambiguity=False,\n",
    "        max_order_f = 5,\n",
    "        max_order_b = 5\n",
    "        )\n",
    "\n",
    "        # Check autonomy condition\n",
    "        _, _, auto = aux.checkAutonomy(S_minus, S_plus)\n",
    "        if not auto:\n",
    "            continue\n",
    "         \n",
    "        # von Neumann growth factor α, β\n",
    "        try:\n",
    "            alpha, beta, x_alpha, p_alpha, x_beta, p_beta = compute_von_neumann_alpha_beta(S_plus, S_minus)\n",
    "        except Exception:\n",
    "            continue\n",
    "        if np.isnan(alpha) or np.isnan(beta):\n",
    "            continue\n",
    "\n",
    "        delta = alpha - 1.0\n",
    "\n",
    "        # check which quota this alpha would fill — skip if full\n",
    "        if delta < -tol_alpha:\n",
    "            if count_lt1 >= quota_lt1:\n",
    "                continue\n",
    "        else:\n",
    "            # delta >= -tol_alpha  --> treat as alpha >= 1 class (includes alpha≈1)\n",
    "            if count_ge1 >= quota_ge1:\n",
    "                continue\n",
    "            \n",
    "        mu = compute_topological_growth_bound(S_minus, alpha)\n",
    "        if abs(mu) < 1e-3:\n",
    "            mu = 0.0\n",
    "\n",
    "        mu_l = compute_lower_topological_growth_bound(S_minus)\n",
    "        if abs(mu_l) < 1e-3:\n",
    "            mu_l = 0.0\n",
    "        \n",
    "        # Kinetics\n",
    "        Y0, kf, kd = Construct_Kinetics(\n",
    "            N_Y, N_R, S_plus, S_minus, degradation=False\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            q_star, lambda_long, J_star = solve_steadystate_by_newton_krylov(\n",
    "                    S_plus, S_minus, N_Y, N_R, Y0, kf)\n",
    "        \n",
    "        except NoConvergence:        \n",
    "            dt = 1e-4\n",
    "            n_steps = 2000000\n",
    "            threshold = 1e-4\n",
    "            extra_steps = 100000\n",
    "            t_eval, Ystar_traj, Yabs_traj, lambdas, N_traj = Solve_Scaled_System(\n",
    "                S_minus, S_plus, Y0, N_Y, N_R,\n",
    "                kf, kd, dt, n_steps, threshold, extra_steps, law = \"MA\")\n",
    "            \n",
    "            lambda_long = compute_long_term_growth_rate(lambdas)\n",
    "        \n",
    "        \n",
    "        if not (np.isfinite(mu) and np.isfinite(lambda_long)):\n",
    "            continue\n",
    "\n",
    "        # ---------- Normalization for the universal bound ----------\n",
    "        # u(S) = max(0, alpha - 1)\n",
    "        delta = alpha - 1.0\n",
    "        u = max(0.0, delta)\n",
    "\n",
    "        # Norm S-\n",
    "        row_sums = np.sum(S_minus, axis=1)\n",
    "        S_minus_norm = np.max(row_sums)\n",
    "\n",
    "        # Norm k\n",
    "        k_norm = 1\n",
    "\n",
    "        B = S_minus_norm * k_norm\n",
    "        if not np.isfinite(B) or B < 1e-12:\n",
    "            continue\n",
    "\n",
    "        lam_tilde = lambda_long / B\n",
    "\n",
    "        # --- record rounded values (1e-4) for saving/comparison only ---\n",
    "        alpha_rec = q1(alpha)\n",
    "        beta_rec = q1(beta)\n",
    "        mu_rec = q1(mu)\n",
    "        mu_l_rec = q1(mu_l)\n",
    "        lambda_rec = q1(lambda_long)\n",
    "        delta_rec = q1(delta)\n",
    "        u_rec = q1(u)\n",
    "        B_rec = q1(B)\n",
    "        lam_tilde_rec = q1(lam_tilde)\n",
    "        # ---------------------------------------------------------------\n",
    "        \n",
    "        # -------- violation check (compare ONLY at 1e-4) --------\n",
    "        is_lt = (delta < -tol_alpha)            # class decided from raw delta\n",
    "        is_ge = (delta >= tol_alpha)           # alpha >= 1 class\n",
    "\n",
    "        viol_lt = is_lt and (delta_rec > lam_tilde_rec) # should satisfy delta <= lambda_tilde\n",
    "        viol_ge = is_ge and (delta_rec < lam_tilde_rec) # should satisfy lambda_tilde <= delta\n",
    "\n",
    "        viol = (viol_lt or viol_ge)\n",
    "        violation_list.append(viol)\n",
    "\n",
    "        if viol_lt:\n",
    "            print(f\"[VIOLATION α<1] realization={successes} α={alpha_rec:.5f} δ={delta_rec:.5f} λ~={lam_tilde_rec:.5f} λ={lambda_rec:.5f} norm={B_rec:.5f}\")\n",
    "        if viol_ge:\n",
    "            print(f\"[VIOLATION α≥1] realization={successes} α={alpha_rec:.5f} δ={delta_rec:.5f} λ~={lam_tilde_rec:.5f} λ={lambda_rec:.5f} norm={B_rec:.5f}\")\n",
    "        # ----------------------------------------------------------\n",
    "\n",
    "\n",
    "        delta_list.append(delta_rec)\n",
    "        u_list.append(u_rec)\n",
    "        B_list.append(B_rec)\n",
    "        lam_tilde_list.append(lam_tilde_rec)\n",
    "        \n",
    "        # save\n",
    "        alpha_list.append(alpha_rec)\n",
    "        beta_list.append(beta_rec)\n",
    "        lambda_list.append(lambda_rec)\n",
    "        mu_list.append(mu_rec)\n",
    "        mu_l_list.append(mu_l_rec)\n",
    "\n",
    "        growth_list.append({\n",
    "            'realization': successes,\n",
    "            'alpha': alpha_rec,\n",
    "            'beta': beta_rec,\n",
    "            'mu': mu_rec,\n",
    "            'mu_low': mu_l_rec,\n",
    "            'lambda': lambda_rec,\n",
    "            'delta': delta_rec,\n",
    "            'lambda_tilde': lam_tilde_rec,\n",
    "            'violation': viol,         \n",
    "        })\n",
    "        S_plus_list.append(S_plus)\n",
    "        S_minus_list.append(S_minus)\n",
    "        kf_list.append(q(kf))\n",
    "        kd_list.append(None if kd is None else q(kd))\n",
    "                \n",
    "        successes = len(alpha_list)\n",
    "\n",
    "        pct = int(100 * successes / total_target)\n",
    "        if pct >= next_pct:\n",
    "            print(f\"Progress: {next_pct}% completed ({successes}/{total_target}).\")\n",
    "            next_pct += 10\n",
    "                \n",
    "        if delta < -tol_alpha:\n",
    "            count_lt1 += 1\n",
    "        else:\n",
    "            count_ge1 += 1\n",
    "        \n",
    "        #print(f\"【{successes}/{quota_ge1+quota_lt1}】  α = {alpha:.5f},  β = {beta:.5f}, μ = {mu:.5f},  λ = {lambda_long:.5f}\")\n",
    "\n",
    "        if (count_ge1 >= quota_ge1 and count_lt1 >= quota_lt1):\n",
    "            print(\"All quotas reached, stop simulation.\")\n",
    "            break\n",
    "            \n",
    "    # check loop        \n",
    "        #print(f\"collect {successes} effective (α, β, mu, λ), end\")\n",
    "\n",
    "    lam_arr = np.array(lambda_list)\n",
    "    mu_arr = np.array(mu_list)\n",
    "    mu_l_arr = np.array(mu_l_list)\n",
    "    \n",
    "    viol_arr = np.array(violation_list, dtype=bool)\n",
    "    any_violation = bool(np.any(viol_arr))\n",
    "    \n",
    "    # =============================\n",
    "    # Two figures:\n",
    "    #   Fig A: alpha < 1  (delta < 0)   bound: delta <= x <= 0\n",
    "    #   Fig B: alpha >= 1 (delta >= 0)  bound: -1 <= x <= delta   (alpha=1 auto included)\n",
    "    # x = lambda_tilde, y = delta\n",
    "    # No titles, no legends\n",
    "    # Save as two separate PDFs in current folder\n",
    "    # =============================\n",
    "    \n",
    "    # -----------------------\n",
    "    # Plot settings\n",
    "    # -----------------------\n",
    "    tick_fs  = 12   # tick numbers font size\n",
    "    label_fs = 14   # axis label font size\n",
    "    \n",
    "    bins_hist = 100          # histogram bins (you can tune)\n",
    "    use_hist  = True        # set False if you only want KDE\n",
    "    use_kde   = False        # set True to overlay KDE curve\n",
    "    \n",
    "    tol_alpha = 1e-4        # must match sampling classification\n",
    "    \n",
    "    out_dir = \"results_order5_fixsize\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    \n",
    "    def pad_range(vmin, vmax, frac=0.07):\n",
    "        span = vmax - vmin\n",
    "        if span < 1e-12:\n",
    "            span = 1.0\n",
    "        p = frac * span\n",
    "        return vmin - p, vmax + p\n",
    "    \n",
    "    def kde_counts_1d(samples, y_grid, bin_width, bw=None):\n",
    "        \"\"\"\n",
    "        Gaussian KDE (manual) -> returns \"expected counts\" per bin-width,\n",
    "        so it overlays nicely with a COUNT histogram.\n",
    "        \"\"\"\n",
    "        samples = np.asarray(samples, dtype=float)\n",
    "        n = samples.size\n",
    "        if n < 2:\n",
    "            return np.zeros_like(y_grid)\n",
    "    \n",
    "        std = samples.std(ddof=1)\n",
    "        if bw is None:\n",
    "            # Silverman's rule\n",
    "            bw = 1.06 * std * (n ** (-1/5)) if std > 1e-12 else 1.0\n",
    "    \n",
    "        diff = (y_grid[:, None] - samples[None, :]) / bw\n",
    "        pdf = np.exp(-0.5 * diff**2).sum(axis=1) / (n * bw * np.sqrt(2*np.pi))\n",
    "    \n",
    "        # convert density -> expected counts per bin-width\n",
    "        return pdf * n * bin_width\n",
    "    \n",
    "    # -----------------------\n",
    "    # Data arrays (no re-simulation)\n",
    "    # -----------------------\n",
    "    delta_arr = np.array(delta_list, dtype=float)\n",
    "    lam_tilde_arr = np.array(lam_tilde_list, dtype=float)\n",
    "    \n",
    "    mask_lt = delta_arr < -tol_alpha           # alpha < 1\n",
    "    mask_ge = delta_arr >= -tol_alpha          # alpha >= 1 (includes alpha≈1)\n",
    "    \n",
    "    # for clean plotting: force alpha≈1 band to delta=0\n",
    "    delta_plot = delta_arr.copy()\n",
    "    delta_plot[np.abs(delta_plot) < tol_alpha] = 0.0\n",
    "    \n",
    "    # -----------------------\n",
    "    # Helper: draw (scatter + feasible shading) + right distribution\n",
    "    # -----------------------\n",
    "    def plot_with_right_distribution(x, y, mode, pdf_name, viol_mask=None, ref_point=None):\n",
    "        \"\"\"\n",
    "        mode = \"lt\"  : alpha<1  bound: y <= x <= 0, y<=0\n",
    "        mode = \"ge\"  : alpha>=1 bound: -1 <= x <= y, y>=0\n",
    "        \"\"\"\n",
    "        fig = plt.figure(figsize=(8.5, 5))\n",
    "        gs = fig.add_gridspec(1, 2, width_ratios=[3.2, 1.0], wspace=0.05)\n",
    "    \n",
    "        ax = fig.add_subplot(gs[0, 0])\n",
    "        axh = fig.add_subplot(gs[0, 1], sharey=ax)\n",
    "\n",
    "        # ---- scatter (black normal, red violations) ----\n",
    "        if x.size:\n",
    "            if viol_mask is None:\n",
    "                ax.scatter(x, y, s=30, edgecolors='k', alpha=0.9)\n",
    "            else:\n",
    "                viol_mask = np.asarray(viol_mask, dtype=bool)\n",
    "                ax.scatter(x[~viol_mask], y[~viol_mask], s=30, edgecolors='k', alpha=0.9)\n",
    "                if np.any(viol_mask):\n",
    "                    ax.scatter(x[viol_mask], y[viol_mask], s=30, color='red', edgecolors='k', alpha=0.95)\n",
    "    \n",
    "        # ---- y limits from data (independent per figure) ----\n",
    "        if y.size:\n",
    "            ymin, ymax = y.min(), y.max()\n",
    "            ymin, ymax = pad_range(ymin, ymax)\n",
    "        else:\n",
    "            ymin, ymax = (-1.0, 1.0)\n",
    "        ax.set_ylim(ymin, ymax)\n",
    "    \n",
    "        # ---- shading + reference lines (NO legend, NO title) ----\n",
    "        if mode == \"lt\":\n",
    "            # NEW strict bound for alpha<1:  -1 <= x <= 0\n",
    "            yy = np.linspace(ymin, ymax, 400)\n",
    "            ax.fill_betweenx(yy, -1.0, 0.0, alpha=0.12)\n",
    "\n",
    "            # strict-bound reference lines (no legend)\n",
    "            ax.axvline(-1.0, ls='--', color='gray')\n",
    "            ax.axvline(0.0,  ls='--', color='gray')\n",
    "\n",
    "            # asymptotic line: delta = lambda_tilde  (draw from (0,0) downwards, clipped to x>=-1)\n",
    "            d_end = max(-1.0, ymin)   # stop at x=-1 or at ymin if higher\n",
    "            if d_end < 0.0:\n",
    "                ax.plot([0.0, d_end], [0.0, d_end],\n",
    "                        ls=':', lw=1.6, color='tab:orange')  # different style/color\n",
    "\n",
    "            # x limits: include [-1,0], but allow showing outliers if any exist\n",
    "            if x.size:\n",
    "                xmin = min(-1.0, x.min())\n",
    "                xmax = max(0.0,  x.max())\n",
    "            else:\n",
    "                xmin, xmax = -1.0, 0.0\n",
    "            ax.set_xlim(*pad_range(xmin, xmax))\n",
    "    \n",
    "        elif mode == \"ge\":\n",
    "            # feasible region: for y in [max(0,ymin), ymax], x in [-1, y]\n",
    "            y_lo = max(0.0, ymin)\n",
    "            if y_lo < ymax:\n",
    "                yy = np.linspace(y_lo, ymax, 400)\n",
    "                ax.fill_betweenx(yy, -1.0, yy, alpha=0.12)\n",
    "    \n",
    "            ax.axvline(-1.0, ls='--', color='gray')\n",
    "            if ymax > 0.0:\n",
    "                ax.plot([0.0, ymax], [0.0, ymax], ls='--', color='gray')  # y=x from origin into positive\n",
    "    \n",
    "            # x limits\n",
    "            if x.size:\n",
    "                xmax = max(x.max(), ymax)\n",
    "            else:\n",
    "                xmax = max(1.0, ymax)\n",
    "            ax.set_xlim(*pad_range(-1.0, xmax))\n",
    "    \n",
    "        # ---- axis labels (font adjustable) ----\n",
    "        ax.set_xlabel(r'$\\tilde{\\Lambda}$', fontsize=label_fs)\n",
    "        ax.set_ylabel(r'$\\delta$', fontsize=label_fs)\n",
    "        ax.grid(linestyle=\"--\", alpha=0.5)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=tick_fs)\n",
    "    \n",
    "        # -----------------------\n",
    "        # Right distribution: histogram + KDE (frequency on x, delta on y)\n",
    "        # -----------------------\n",
    "        axh.grid(linestyle=\"--\", alpha=0.3)\n",
    "        axh.tick_params(axis='both', which='major', labelsize=tick_fs)\n",
    "    \n",
    "        # hide duplicated y tick labels on the right panel (keeps alignment clean)\n",
    "        plt.setp(axh.get_yticklabels(), visible=False)\n",
    "    \n",
    "        if y.size:\n",
    "            # choose histogram range to match main y-lims\n",
    "            y_range = ymax - ymin\n",
    "            bin_width = y_range / bins_hist\n",
    "    \n",
    "            if use_hist:\n",
    "                axh.hist(\n",
    "                    y,\n",
    "                    bins=bins_hist,\n",
    "                    range=(ymin, ymax),\n",
    "                    orientation=\"horizontal\",\n",
    "                    density=False,         # frequency counts\n",
    "                    alpha=0.35,\n",
    "                    edgecolor=\"none\"\n",
    "                )\n",
    "    \n",
    "            if use_kde:\n",
    "                yy = np.linspace(ymin, ymax, 400)\n",
    "                kde_x = kde_counts_1d(y, yy, bin_width=bin_width, bw=None)\n",
    "                axh.plot(kde_x, yy, lw=1.5)\n",
    "    \n",
    "            axh.set_xlabel(\"count\", fontsize=label_fs)\n",
    "        else:\n",
    "            axh.set_xlabel(\"count\", fontsize=label_fs)\n",
    "\n",
    "        # ---- optional reference red point (only when no violations globally) ----\n",
    "        if ref_point is not None:\n",
    "            y_ref, x_ref = ref_point[0], ref_point[1]   # y=delta, x=lambda_tilde\n",
    "            # only plot it on the matching panel\n",
    "            if (mode == \"lt\" and y_ref < -tol_alpha) or (mode == \"ge\" and y_ref >= -tol_alpha):\n",
    "                ax.scatter([x_ref], [y_ref], s=60, color='red', edgecolors='k', zorder=5)\n",
    "\n",
    "        # save\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(os.path.join(out_dir, pdf_name), bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "\n",
    "    vA = viol_arr[mask_lt]\n",
    "    vB = viol_arr[mask_ge]\n",
    "    # -----------------------\n",
    "    # FIG A: alpha < 1\n",
    "    # -----------------------\n",
    "    xA = lam_tilde_arr[mask_lt]\n",
    "    yA = delta_plot[mask_lt]\n",
    "    plot_with_right_distribution(xA, yA, mode=\"lt\",\n",
    "                                 pdf_name=\"bound_alpha_lt1_with_delta_dist.pdf\",\n",
    "                                 viol_mask=vA, ref_point=None)\n",
    "    # -----------------------\n",
    "    # FIG B: alpha >= 1 (merged)\n",
    "    # -----------------------\n",
    "    xB = lam_tilde_arr[mask_ge]\n",
    "    yB = delta_plot[mask_ge]\n",
    "    plot_with_right_distribution(xB, yB, mode=\"ge\",\n",
    "                                 pdf_name=\"bound_alpha_ge1_with_delta_dist.pdf\",\n",
    "                                 viol_mask=vB, ref_point=None)\n",
    "\n",
    "    save_all_results(\n",
    "        base_folder='results_order5_fixsize',\n",
    "        growth_list=growth_list,\n",
    "        S_plus_list=S_plus_list,\n",
    "        S_minus_list=S_minus_list,\n",
    "        kf_list=kf_list,\n",
    "        kd_list=kd_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8848bf43-8d37-4d0d-9d28-7f59e5822182",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T11:56:29.790725Z",
     "iopub.status.busy": "2026-02-13T11:56:29.790535Z",
     "iopub.status.idle": "2026-02-13T17:42:44.807384Z",
     "shell.execute_reply": "2026-02-13T17:42:44.806754Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/tmp.5878091/ipykernel_1494728/4125688269.py:99: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      " improvement from the last ten iterations.\n",
      "  LB = fsolve(g, 2).item()  # Lower bound for α, β\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/naiss2025-22-468/bamm_venv/lib/python3.12/site-packages/scipy/optimize/_nonlin.py:375: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  and dx_norm/self.x_rtol <= x_norm))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/tmp.5878091/ipykernel_1494728/4125688269.py:98: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      " improvement from the last ten iterations.\n",
      "  UB = fsolve(f, 1).item()  # Upper bound for α, β\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/naiss2025-22-468/bamm_venv/lib/python3.12/site-packages/scipy/optimize/_nonlin.py:681: RuntimeWarning: overflow encountered in dot\n",
      "  return np.dot(self.collapsed.T.conj(), v)\n",
      "/mimer/NOBACKUP/groups/naiss2025-22-468/bamm_venv/lib/python3.12/site-packages/scipy/optimize/_nonlin.py:950: RuntimeWarning: divide by zero encountered in divide\n",
      "  d = v / vdot(df, v)\n",
      "/mimer/NOBACKUP/groups/naiss2025-22-468/bamm_venv/lib/python3.12/site-packages/scipy/optimize/_nonlin.py:950: RuntimeWarning: invalid value encountered in divide\n",
      "  d = v / vdot(df, v)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/naiss2025-22-468/bamm_venv/lib/python3.12/site-packages/scipy/optimize/_nonlin.py:698: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.collapsed += c[:,None] * d[None,:].conj()\n",
      "/mimer/NOBACKUP/groups/naiss2025-22-468/bamm_venv/lib/python3.12/site-packages/scipy/optimize/_nonlin.py:675: RuntimeWarning: invalid value encountered in dot\n",
      "  return np.dot(self.collapsed, v)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 10% completed (10000/100000).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VIOLATION α<1] realization=11336 α=0.98910 δ=-0.01090 λ~=-0.01350 λ=-0.18840 norm=14.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 20% completed (20000/100000).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VIOLATION α<1] realization=20189 α=0.89440 δ=-0.10560 λ~=-0.11480 λ=-0.57380 norm=5.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 30% completed (30000/100000).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 40% completed (40000/100000).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VIOLATION α<1] realization=46391 α=0.94870 δ=-0.05130 λ~=-0.05820 λ=-0.40760 norm=7.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 50% completed (50000/100000).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VIOLATION α<1] realization=51056 α=0.96820 δ=-0.03180 λ~=-0.03650 λ=-0.43820 norm=12.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 60% completed (60000/100000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/naiss2025-22-468/bamm_venv/lib/python3.12/site-packages/scipy/optimize/_nonlin.py:721: RuntimeWarning: invalid value encountered in multiply\n",
      "  Gm += c[:,None]*d[None,:].conj()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VIOLATION α<1] realization=67471 α=0.99600 δ=-0.00400 λ~=-0.00460 λ=-0.08820 norm=19.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 70% completed (70000/100000).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VIOLATION α<1] realization=75670 α=0.96820 δ=-0.03180 λ~=-0.03980 λ=-0.67670 norm=17.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VIOLATION α<1] realization=79008 α=0.96820 δ=-0.03180 λ~=-0.04840 λ=-0.53280 norm=11.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 80% completed (80000/100000).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VIOLATION α<1] realization=84264 α=0.96820 δ=-0.03180 λ~=-0.03590 λ=-0.35930 norm=10.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VIOLATION α<1] realization=86886 α=0.99150 δ=-0.00850 λ~=-0.00990 λ=-0.15920 norm=16.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 90% completed (90000/100000).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VIOLATION α<1] realization=93781 α=0.99350 δ=-0.00650 λ~=-0.01100 λ=-0.19730 norm=18.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VIOLATION α<1] realization=94285 α=0.99690 δ=-0.00310 λ~=-0.00460 λ=-0.04140 norm=9.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VIOLATION α<1] realization=96076 α=0.96820 δ=-0.03180 λ~=-0.04670 λ=-0.51330 norm=11.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 100% completed (100000/100000).\n",
      "All quotas reached, stop simulation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/tmp.5878091/ipykernel_1494728/4239304706.py:422: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  fig.tight_layout()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/tmp.5878091/ipykernel_1494728/4239304706.py:422: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  fig.tight_layout()\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main_order2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5304e174-5fc5-4bfb-afc3-8f156139a751",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
